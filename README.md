# ğŸ§  Self-Supervised Learning on MNIST

This repository showcases a self-supervised learning pipeline applied to the MNIST dataset using multiple algorithms, all implemented from scratch with PyTorch. The goal is to learn meaningful representations **without using labels**, and later evaluate them via classification.

---

## ğŸ“Œ Overview

Implemented self-supervised methods:

- âœ… **Autoencoder** (Encoder-Decoder) â€” learns by reconstructing input images.
- ğŸ”„ **Rotation Prediction** â€” trains a model to predict the rotation angle of images (0Â°, 90Â°, 180Â°, 270Â°).
- ğŸ”— **SimCLR (Contrastive Learning)** â€” learns by contrasting positive and negative pairs using `NTXentLoss` from the [Lightly](https://github.com/lightly-ai/lightly) library.

Each method is evaluated by:
- Visualizing **loss curves**
- Measuring **per-class accuracy**
- Applying **dimensionality reduction (PCA / t-SNE)** to visualize latent space
- Showing **class distribution balance**

---

## ğŸ—‚ï¸ Project Structure

```
mnist-self-supervised/
â”œâ”€â”€ autoencoder.py             # Encoder-decoder model
â”œâ”€â”€ rotate_prediction.py       # Rotation-based self-supervision
â”œâ”€â”€ simclr.py                  # SimCLR model with NTXentLoss
â”œâ”€â”€ data_loader.py             # Augmentations and MNIST loading
â”œâ”€â”€ linear_eval.py             # Classifier training on frozen encoder
â”œâ”€â”€ utils.py                   # Loss functions, accuracy, visualizations
â”œâ”€â”€ train.py                   # Main training logic
â””â”€â”€ README.md                  # Project documentation
```

---

## ğŸ“¦ Requirements

Install all dependencies using pip:

```bash
pip install torch torchvision matplotlib scikit-learn lightly tqdm
```

---

## ğŸ“‚ Dataset

- **MNIST** (28x28 grayscale handwritten digits)
- Loaded via `torchvision.datasets.MNIST`
- Augmentations used:
  - Random rotations (for rotation task)
  - Cropping, flipping, jittering (for SimCLR)
- The dataset is balanced, and class distributions were visualized to confirm it.

---

## ğŸ§ª Method Details

### 1. Autoencoder
- Architecture: Simple CNN encoder + symmetric decoder
- Trained using MSE loss between input and reconstructed output
- No labels used

### 2. Rotation Prediction
- Input images are rotated randomly
- Model is trained to predict one of 4 rotation classes
- Supervision is self-generated from the rotation itself

### 3. SimCLR
- Uses two random augmentations per image to create a positive pair
- Contrastive loss: NT-Xent (`lightly.loss.NTXentLoss`)
- Negative pairs sampled within batch

---

## ğŸ“Š Evaluation

- ğŸ“‰ **Loss Curves**: Each modelâ€™s training loss was tracked and plotted
- ğŸ¯ **Accuracy Per Class**: Evaluated using a linear classifier on top of the frozen encoder
- ğŸŒˆ **Latent Space Visualization**: PCA and t-SNE used to inspect learned representations
- ğŸ“Š **Class Distribution**: Verified uniformity across classes before training

---

## ğŸ“ˆ Results Summary

| Method            | Stable Loss | Accuracy | Notes                          |
|-------------------|-------------|----------|--------------------------------|
| Autoencoder       | âœ… Yes       | High   | Good for simple representations |
| Rotation          | âš ï¸ Noisy     | Medium   | Struggles with similar digits (e.g. 3 vs 9) |
| SimCLR            | âœ… Stable    | Medium     | Best generalization & low overfitting |

---

## ğŸš§ Future Work

- Use CIFAR-10 or SVHN for more complex experiments
- Apply deeper architectures like ResNet
- Add semi-supervised finetuning

---

## ğŸ‘¤ Author

**Pooyan Jamshidi**  
A self-supervised learning enthusiast exploring representation learning with simple datasets and custom implementations.

---

## ğŸ“ License

This project is open-source and available under the MIT License.
